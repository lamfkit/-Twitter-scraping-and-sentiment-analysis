{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "from Scweet.scweet import scrape\n",
    "from Scweet.user import get_user_information, get_users_following, get_users_followers\n",
    "import pandas as pd\n",
    "import re\n",
    "import psycopg2\n",
    "import psycopg2.extras as extras\n",
    "from sqlalchemy import create_engine\n",
    "import time\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Def function------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_strnumber(number):\n",
    "    if type(number) == str:\n",
    "        if number.find('萬') != -1:\n",
    "            number = number.replace('萬', '')\n",
    "            number = float(number) * 10000\n",
    "            return int(number)\n",
    "\n",
    "        if number.find(',') != -1:\n",
    "            number = number.replace(',', '')\n",
    "            return int(number)\n",
    "\n",
    "        if number.find('K') != -1:\n",
    "            number = number.replace('K', '')\n",
    "            number = float(number) * 1000\n",
    "            return int(number)\n",
    "\n",
    "        elif number.find('k') != -1:\n",
    "            number = number.replace('k', '')\n",
    "            number = float(number) * 1000\n",
    "            return int(number)\n",
    "\n",
    "        if number.find('M') != -1:\n",
    "            number = number.replace('M', '')\n",
    "            number = float(number) * 1000000\n",
    "            return int(number)\n",
    "\n",
    "        elif number.find('m') != -1:\n",
    "            number = number.replace('m', '')\n",
    "            number = float(number) * 1000000\n",
    "            return int(number)\n",
    "\n",
    "    return int(number)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def delete_add(username):\n",
    "    if type(username) == str:\n",
    "        if username.find('@') != -1:\n",
    "            username = username.replace('@', '')\n",
    "            return username"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanTweet(Tweet):\n",
    "   Tweet = re.sub(\"[\"u\"\\U0001F600-\\U0001F64F\"\"]\",'',Tweet)\n",
    "   Tweet = re.sub(\"[\"u\"\\U0001F300-\\U0001F5FF\"\"]\",'',Tweet)\n",
    "   Tweet = re.sub(\"[\"u\"\\U0001F680-\\U0001F6FF\"\"]\",'',Tweet)\n",
    "   Tweet = re.sub(\"[\"u\"\\U0001F1E0-\\U0001F1FF\"\"]\",'',Tweet)\n",
    "   Tweet = re.sub('@[A-Za-z0–9_]+','',Tweet)\n",
    "   Tweet = re.sub('RT[\\s]+','',Tweet)\n",
    "   Tweet = re.sub('#','',Tweet)\n",
    "   Tweet = re.sub('https?://\\S+','',Tweet)\n",
    "   Tweet = re.sub('&amp;','and',Tweet)\n",
    "   Tweet = re.sub(' +',' ',Tweet)\n",
    "   Tweet = re.sub(\"[([].*?[)]]\",\"\",Tweet)\n",
    "   Tweet = re.sub(\"\\n\",\" \", Tweet)\n",
    "   Tweet = re.sub(\"^[^A-Za-z0–9]+\",\"\",Tweet)\n",
    "   Tweet = Tweet.strip()\n",
    "   Tweet = Tweet.lower()\n",
    "   return Tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def connect(params_dic):\n",
    "    \"\"\" Connect to the PostgreSQL database server \"\"\"\n",
    "    conn = None\n",
    "    try:\n",
    "        # connect to the PostgreSQL server\n",
    "        print('Connecting to the PostgreSQL database...')\n",
    "        conn = psycopg2.connect(**params_dic)\n",
    "    except (Exception, psycopg2.DatabaseError) as error:\n",
    "        print(error)\n",
    "        sys.exit(1)\n",
    "    print(\"Connection successful\")\n",
    "    return conn\n",
    "\n",
    "def execute_values(conn, df, table):\n",
    "    \"\"\"\n",
    "    Using psycopg2.extras.execute_values() to insert the dataframe\n",
    "    \"\"\"\n",
    "    # Create a list of tupples from the dataframe values\n",
    "    tuples = [tuple(x) for x in df.to_numpy()]\n",
    "    # Comma-separated dataframe columns\n",
    "    cols = ','.join(list(df.columns))\n",
    "    # SQL quert to execute\n",
    "    query  = \"INSERT INTO %s(%s) VALUES %%s\" % (table, cols)\n",
    "    cursor = conn.cursor()\n",
    "    try:\n",
    "        extras.execute_values(cursor, query, tuples)\n",
    "        conn.commit()\n",
    "    except (Exception, psycopg2.DatabaseError) as error:\n",
    "        print(\"Error: %s\" % error)\n",
    "        conn.rollback()\n",
    "        cursor.close()\n",
    "        return 1\n",
    "    print(\"execute_values() done\")\n",
    "    cursor.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Execution-------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    time_now = time.strftime(\"%H:%M:%S\", time.localtime()) # refresh time\n",
    "    if time_now == \"03:18:00\": #set the daily timer\n",
    "        today = datetime.date.today()\n",
    "        formatted_today = today.strftime('20%y-%m-%d')\n",
    "        tmr = (datetime.date.today()+datetime.timedelta(days=+1)).strftime('20%y-%m-%d')\n",
    "        ytd = (datetime.date.today()+datetime.timedelta(days=-1)).strftime('20%y-%m-%d')\n",
    "    \n",
    "        data = scrape(words=['CCP'], since=str(ytd), until=str(today), from_account = None,interval=1, \n",
    "      headless=False, display_type=\"Top\", save_images=False, proxy = None, save_dir = 'outputs',\n",
    "             resume=False, filter_replies=True, proximity=False)\n",
    "\n",
    "        data2 = data.copy()\n",
    "        data2['Timestamp'] = pd.to_datetime(data[\"Timestamp\"])\n",
    "\n",
    "        for i, row  in data2.iterrows():\n",
    "\n",
    "            if len(row['Comments']) == 0:\n",
    "                data2.loc[i, 'Comments'] = 0\n",
    "            if len(row['Likes']) == 0:\n",
    "                data2.loc[i, 'Likes'] = 0\n",
    "            if len(row['Retweets']) == 0:\n",
    "                data2.loc[i, 'Retweets'] = 0\n",
    "\n",
    "        data3 = data2.copy()\n",
    "\n",
    "        for i, row  in data3.iterrows():\n",
    "            data3.loc[i, 'Comments'] = convert_strnumber(data2['Comments'][i])\n",
    "            data3.loc[i, 'Likes'] = convert_strnumber(data2['Likes'][i])\n",
    "            data3.loc[i, 'Retweets'] = convert_strnumber(data2['Retweets'][i])\n",
    "\n",
    "        clean_data = data3.copy()\n",
    "\n",
    "        clean_data['Timestamp'] = clean_data['Timestamp'].dt.date\n",
    "\n",
    "        for i, row  in clean_data.iterrows():\n",
    "            clean_data.loc[i, 'UserName'] = delete_add(data3['UserName'][i])\n",
    "\n",
    "        clean_data2 = clean_data[['UserName', 'Timestamp', 'Embedded_text', 'Comments', 'Likes', 'Retweets']]\n",
    "\n",
    "        clean_data3 = clean_data2.copy()\n",
    "\n",
    "        for i, row  in clean_data2.iterrows():\n",
    "            clean_data3.loc[i, 'Embedded_text'] = cleanTweet(clean_data2['Embedded_text'][i])\n",
    "\n",
    "        clean_data3.to_csv('clean_data3.csv', index=False)\n",
    "\n",
    "        hostname = 'localhost'\n",
    "        database = 'twitter'\n",
    "        username = 'postgres'\n",
    "        pwd = 'admin'\n",
    "        port_id = 5432\n",
    "        conn = None\n",
    "        cur = None\n",
    "\n",
    "        try:\n",
    "            conn = psycopg2.connect(\n",
    "                        host = hostname,\n",
    "                        dbname = database,\n",
    "                        user = username,\n",
    "                        password= pwd,\n",
    "                        port = port_id)\n",
    "\n",
    "            cur = conn.cursor() \n",
    "\n",
    "            create_script =  '''CREATE TABLE IF NOT EXISTS twitter (\n",
    "                                    UserName    varchar(250) NOT NULL,\n",
    "                                    Timestamp   date NOT NULL,\n",
    "                                    Embedded_text varchar(1000),\n",
    "                                    Comments    int NOT NULL,\n",
    "                                    Likes       int NOT NULL,\n",
    "                                    Retweets    int NOT NULL)'''\n",
    "                            \n",
    "            cur.execute(create_script)\n",
    "\n",
    "\n",
    "            conn.commit()\n",
    "        except Exception as error:\n",
    "            print(error)\n",
    "        finally:\n",
    "            if cur is not None: \n",
    "                cur.close()\n",
    "            if conn is not None:\n",
    "                conn.close()\n",
    "\n",
    "        param_dic = {\n",
    "            \"host\"      : \"localhost\",\n",
    "            \"database\"  : \"twitter\",\n",
    "            \"user\"      : \"postgres\",\n",
    "            \"password\"  : \"admin\"\n",
    "        }\n",
    "\n",
    "        # Read the csv file\n",
    "        # Read your dataframe\n",
    "        df = clean_data3.copy()\n",
    "        # Connect to the database\n",
    "        conn = connect(param_dic)\n",
    "        # Run the execute_many strategy\n",
    "        execute_values(conn, df, 'twitter')\n",
    "        # Close the connection\n",
    "        conn.close()\n",
    "\n",
    "\n",
    "        engine = create_engine(\"postgresql+psycopg2://postgres:admin@localhost:5432/twitter\")\n",
    "\n",
    "        sql_sum = pd.read_sql_query(''' SELECT timestamp, sum(comments) as total_comments, sum(likes) as total_likes, sum(retweets) as total_retweets\n",
    "                       FROM twitter\n",
    "                       GROUP BY timestamp\n",
    "                       order by timestamp\n",
    "                    ''', engine)\n",
    "\n",
    "\n",
    "        sql_all = pd.read_sql_query(''' SELECT *\n",
    "                       FROM twitter\n",
    "                    ''', engine)\n",
    "\n",
    "        dfword = sql_all.copy()\n",
    "\n",
    "        # create a function to ge the subjectivity\n",
    "        def getSubjectivity(text):\n",
    "            return TextBlob(text).sentiment.subjectivity\n",
    "\n",
    "        # Create a function to get the polarity\n",
    "        def getPolarity(text):\n",
    "            return TextBlob(text).sentiment.polarity\n",
    "\n",
    "        # Create two new column\n",
    "        dfword['Subjectivity'] = sql_all['embedded_text'].apply(getSubjectivity)\n",
    "\n",
    "        dfword['Polarity'] = sql_all['embedded_text'].apply(getPolarity)\n",
    "\n",
    "        # create function for negative positive and neutral\n",
    "        def getAnalysis(score):\n",
    "            if score < 0:\n",
    "                return 'Negative'\n",
    "            elif score == 0:\n",
    "                return 'Neutral'\n",
    "            else:\n",
    "                return 'Positive'\n",
    "\n",
    "        dfword['Analysis'] = dfword['Polarity'].apply(getAnalysis)\n",
    "\n",
    "        dfword_analysis = dfword.copy()\n",
    "\n",
    "        twitter_sentiment = dfword_analysis[['username', 'timestamp', 'embedded_text', 'Subjectivity', 'Polarity', 'Analysis']]\n",
    "\n",
    "        twitter_sentiment.to_csv('twitter_sentiment.csv', index=False)\n",
    "\n",
    "        \n",
    "        hostname = 'localhost'\n",
    "        database = 'twitter'\n",
    "        username = 'postgres'\n",
    "        pwd = 'admin'\n",
    "        port_id = 5432\n",
    "        conn = None\n",
    "        cur = None\n",
    "\n",
    "        try:\n",
    "            conn = psycopg2.connect(\n",
    "                        host = hostname,\n",
    "                        dbname = database,\n",
    "                        user = username,\n",
    "                        password= pwd,\n",
    "                        port = port_id)\n",
    "\n",
    "            cur = conn.cursor() \n",
    "\n",
    "            create_script =  '''CREATE TABLE IF NOT EXISTS twitter_sentiment (\n",
    "                            userName      varchar(250) NOT NULL,\n",
    "                            timestamp     date NOT NULL,\n",
    "                            embedded_text varchar(1000),\n",
    "                            Subjectivity  float,\n",
    "                            Polarity      float,\n",
    "                            Analysis      varchar(50)\n",
    "                            )'''\n",
    "                            \n",
    "            cur.execute(create_script)\n",
    "\n",
    "\n",
    "            conn.commit()\n",
    "        except Exception as error:\n",
    "            print(error)\n",
    "        finally:\n",
    "            if cur is not None: \n",
    "                cur.close()\n",
    "            if conn is not None:\n",
    "                conn.close()\n",
    "\n",
    "        # Read the csv file\n",
    "        # Read your dataframe\n",
    "        df1 = twitter_sentiment.copy()\n",
    "        # Connect to the database\n",
    "        conn = connect(param_dic)\n",
    "        # Run the execute_many strategy\n",
    "        execute_values(conn, df1, 'twitter_sentiment')\n",
    "        # Close the connection\n",
    "        conn.close()\n",
    "\n",
    "        print('Done')\n",
    "\n",
    "        time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping on headless mode.\n",
      "looking for tweets between 2022-09-30 and 2022-10-01 ...\n",
      " path : https://twitter.com/search?q=(CCP)%20until%3A2022-10-01%20since%3A2022-09-30%20%20-filter%3Areplies&src=typed_query\n",
      "scroll  1\n",
      "scroll  2\n",
      "looking for tweets between 2022-10-01 and 2022-10-02 ...\n",
      " path : https://twitter.com/search?q=(CCP)%20until%3A2022-10-02%20since%3A2022-10-01%20%20-filter%3Areplies&src=typed_query\n",
      "scroll  1\n",
      "scroll  2\n",
      "looking for tweets between 2022-10-02 and 2022-10-03 ...\n",
      " path : https://twitter.com/search?q=(CCP)%20until%3A2022-10-03%20since%3A2022-10-02%20%20-filter%3Areplies&src=typed_query\n",
      "scroll  1\n",
      "scroll  2\n",
      "looking for tweets between 2022-10-03 and 2022-10-04 ...\n",
      " path : https://twitter.com/search?q=(CCP)%20until%3A2022-10-04%20since%3A2022-10-03%20%20-filter%3Areplies&src=typed_query\n",
      "scroll  1\n",
      "scroll  2\n",
      "looking for tweets between 2022-10-04 and 2022-10-05 ...\n",
      " path : https://twitter.com/search?q=(CCP)%20until%3A2022-10-05%20since%3A2022-10-04%20%20-filter%3Areplies&src=typed_query\n",
      "scroll  1\n",
      "scroll  2\n",
      "looking for tweets between 2022-10-05 and 2022-10-06 ...\n",
      " path : https://twitter.com/search?q=(CCP)%20until%3A2022-10-06%20since%3A2022-10-05%20%20-filter%3Areplies&src=typed_query\n",
      "scroll  1\n",
      "scroll  2\n",
      "looking for tweets between 2022-10-06 and 2022-10-07 ...\n",
      " path : https://twitter.com/search?q=(CCP)%20until%3A2022-10-07%20since%3A2022-10-06%20%20-filter%3Areplies&src=typed_query\n",
      "scroll  1\n",
      "scroll  2\n"
     ]
    }
   ],
   "source": [
    "data = scrape(words=['CCP'], since=\"2022-09-30\", until=\"2022-10-07\", from_account = None,interval=1, \n",
    "      headless=False, display_type=\"Top\", save_images=False, proxy = None, save_dir = 'outputs',\n",
    "             resume=False, filter_replies=True, proximity=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_sum = pd.read_sql_query(''' SELECT timestamp, sum(comments) as total_comments, sum(likes) as total_likes, sum(retweets) as total_retweets\n",
    "                       FROM twitter\n",
    "                       GROUP BY timestamp\n",
    "                       order by timestamp\n",
    "                    ''', engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x = sql_sum['timestamp']\n",
    "b = sql_sum['total_comments']\n",
    "c = sql_sum['total_likes']\n",
    "d = sql_sum['total_retweets']\n",
    "plt.title('Trend')\n",
    "plt.plot(x,b , color = 'red' , label = 'total comment')\n",
    "plt.plot(x,c , color = 'blue', label = 'total likes')\n",
    "plt.plot(x,d , color = 'orange', label = 'total retweet')\n",
    "plt.legend()\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Quantity')\n",
    "\n",
    "fig1 = plt.gcf()\n",
    "fig1.set_size_inches(18.5, 10.5)\n",
    "\n",
    "fig1.savefig('Trend.png', dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sentiment Analysis-------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "engine = create_engine(\"postgresql+psycopg2://postgres:admin@localhost:5432/twitter\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_all = pd.read_sql_query(''' SELECT * FROM twitter_sentiment''', engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_all.to_csv('sentiment_all.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "countbydate = pd.read_sql_query(''' SELECT timestamp, COUNT(analysis)\n",
    "                                      FROM twitter_sentiment\n",
    "                                      GROUP BY timestamp\n",
    "                                      ORDER BY timestamp\n",
    "                    ''', engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_count_analysis = pd.read_sql_query(''' SELECT timestamp, analysis, COUNT(analysis)\n",
    "                                      FROM twitter_sentiment\n",
    "                                      GROUP BY timestamp, analysis\n",
    "                                      ORDER BY timestamp\n",
    "                    ''', engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_analysis = pd.read_sql_query(''' SELECT timestamp, COUNT(analysis) as total\n",
    "                                      FROM twitter_sentiment\n",
    "                                      GROUP BY timestamp\n",
    "                                      ORDER BY timestamp\n",
    "                    ''', engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "countnegative = pd.read_sql_query(''' SELECT timestamp, analysis, COUNT(analysis) as negative\n",
    "                                      FROM twitter_sentiment\n",
    "                                      WHERE analysis = 'Negative'\n",
    "                                      GROUP BY timestamp, analysis\n",
    "                                      ORDER by timestamp\n",
    "                    ''', engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "countneutral = pd.read_sql_query(''' SELECT timestamp, analysis, COUNT(analysis) as neutral\n",
    "                                      FROM twitter_sentiment\n",
    "                                      WHERE analysis = 'Neutral'\n",
    "                                      GROUP BY timestamp, analysis\n",
    "                                      ORDER by timestamp\n",
    "                    ''', engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "countpositive = pd.read_sql_query(''' SELECT timestamp, analysis, COUNT(analysis) as positive\n",
    "                                      FROM twitter_sentiment\n",
    "                                      WHERE analysis = 'Positive'\n",
    "                                      GROUP BY timestamp, analysis\n",
    "                                      ORDER by timestamp\n",
    "                    ''', engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "date234 = countpositive['timestamp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "mark234 = countpositive['positive'] / (countnegative['negative'] + countpositive['positive'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_percentage = pd.concat([date234, mark234], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_percentage.rename(columns=({ 'timestamp': 'timestamp', 0: 'count'}), inplace=True,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "date1 = count_analysis['timestamp']\n",
    "datetotal = count_analysis['total']\n",
    "datepositive = countpositive['positive']\n",
    "datenegative = countnegative['negative']\n",
    "dateneeutral = countneutral['neutral']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_count = pd.concat([date1, datetotal, datepositive, datenegative, dateneeutral], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_bydate = pd.read_sql_query(''' SELECT timestamp,analysis, AVG(polarity)\n",
    "                                      FROM twitter_sentiment\n",
    "                                      GROUP BY timestamp, analysis\n",
    "                                      ORDER by timestamp\n",
    "                    ''', engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_bydate= pd.read_sql_query(''' SELECT timestamp,analysis, AVG(polarity)\n",
    "                                      FROM twitter_sentiment\n",
    "                                      WHERE analysis <> 'Neutral'\n",
    "                                      GROUP BY timestamp, analysis\n",
    "                                      ORDER by timestamp\n",
    "                    ''', engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "plt.title('Trend')\n",
    "plt.plot(countnegative['timestamp'],countnegative['negative'] , color = 'red' , label = 'Negative')\n",
    "plt.plot(countneutral['timestamp'],countneutral['neutral'] , color = 'orange', label = 'Neutral')\n",
    "plt.plot(countpositive['timestamp'],countpositive['positive'] , color = 'blue', label = 'Positive')\n",
    "plt.plot(count_analysis['timestamp'],count_analysis['total'] , color = 'green', label = 'Total')\n",
    "plt.legend()\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Quantity')\n",
    "\n",
    "fig2 = plt.gcf()\n",
    "fig2.set_size_inches(18.5, 10.5)\n",
    "\n",
    "fig2.savefig('AlltypeSentiment_Trend.png', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x = sentiment_percentage['timestamp']\n",
    "d = sentiment_percentage['count']\n",
    "plt.title('Sentiment Trend')\n",
    "plt.plot(x,d , color = 'orange', label = 'Sentiment Percentage')\n",
    "plt.legend()\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Sentiment Percentage')\n",
    "\n",
    "fig3 = plt.gcf()\n",
    "fig3.set_size_inches(18.5, 10.5)\n",
    "\n",
    "fig3.savefig('POS_percentage_Sentiment_Trend.png', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "fig4 = sns.barplot(x=\"timestamp\", hue=\"analysis\", y=\"count\", data=daily_count_analysis)\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Quantity\")\n",
    "plt.title(\"Sentiment Type\")\n",
    "plt.show(fig4)\n",
    "\n",
    "fig4.figure.savefig('Sentiment_Type_countdate.png', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from email.mime.application import MIMEApplication\n",
    "from email.mime.base import MIMEBase\n",
    "from email.mime.multipart import MIMEMultipartP\n",
    "from email.mime.nonmultipart import MIMENonMultipart\n",
    "from email.mime.text import MIMEText\n",
    "from email.mime.image import MIMEImage\n",
    "from importlib.resources import path\n",
    "from pathlib import Path\n",
    "import smtplib\n",
    "content = MIMEMultipart()  #建立MIMEMultipart物件\n",
    "content[\"subject\"] = \"Graph Analysis on 11 Oct\"  #郵件標題\n",
    "content[\"from\"] = \"sender email address\"  #寄件者\n",
    "content[\"to\"] = \"receiver email address\" #收件者\n",
    "content.attach(MIMEText(\"The Newest Graph Analysis Has Been Outed\"))  #郵件內容\n",
    " # 郵件圖片內容\n",
    "#content.attach(MIMEApplication(Path(\"/Users/cyrus/Desktop/Airflow/clean_data3.csv\").read_bytes()))\n",
    "# Check and revise below path attachmeent file lcoation\n",
    "content.attach(MIMEImage(Path(\"/Twitter/Scweet-master/Trend.png\").read_bytes()))\n",
    "content.attach(MIMEImage(Path(\"/Twitter/Scweet-master/AlltypeSentiment_Trend.png\").read_bytes()))\n",
    "content.attach(MIMEImage(Path(\"/Twitter/Scweet-master/POS_percentage_Sentiment_Trend.png\").read_bytes()))\n",
    "content.attach(MIMEImage(Path(\"/Twitter/Scweet-master/Sentiment_Type_countdate.png\").read_bytes()))\n",
    "with smtplib.SMTP(host=\"smtp.gmail.com\", port=\"587\") as smtp:  # 設定SMTP伺服器\n",
    "    try:\n",
    "        smtp.ehlo()  # 驗證SMTP伺服器\n",
    "        smtp.starttls()  # 建立加密傳輸\n",
    "        smtp.login(\"fungwai0316@gmail.com\", \"gdxcouskuhcnkwqc\")  # 登入寄件者gmail\n",
    "        smtp.send_message(content)  # 寄送郵件\n",
    "        print(\"Complete!\")\n",
    "    except Exception as e:\n",
    "        print(\"Error message: \", e)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
